{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\") \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "from os import listdir\n",
    "import seaborn as sb\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.utils import resample\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import precision_score, recall_score,roc_auc_score,accuracy_score,confusion_matrix,f1_score,log_loss\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from scipy.stats import randint as sp_randint\n",
    "import xgboost as xgb\n",
    "from sklearn.utils import compute_class_weight\n",
    "import math\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from scipy.sparse import hstack\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from itertools import repeat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from statistics import mode,mean,stdev,variance\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"D:\\vysh\\Hard_drive_failure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get Test Data - raw_input, target_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of test_data:  (1537, 17)\n"
     ]
    }
   ],
   "source": [
    "df_segate_backtrack=pd.read_csv(\"df_segate_backtrack.csv\")\n",
    "features=['date', 'model', 'serial_number', 'capacity_bytes', 'failure',\n",
    "       'smart_5_raw', 'smart_9_raw', 'smart_12_raw', 'smart_187_raw',\n",
    "       'smart_188_raw', 'smart_190_raw', 'smart_193_raw', 'smart_194_raw',\n",
    "       'smart_197_raw', 'smart_198_raw', 'smart_199_raw', 'smart_241_raw',\n",
    "       'smart_242_raw']\n",
    "df_segate_backtrack=df_segate_backtrack[features]\n",
    "\n",
    "#selecting different serial number hard drives (some working, some failed)\n",
    "serial_numbers=list(df_segate_backtrack[df_segate_backtrack['failure']==0].serial_number.unique()[0:20])\n",
    "serial_numbers.extend(list(df_segate_backtrack[df_segate_backtrack['failure']==1].serial_number.unique()[0:20]))\n",
    "\n",
    "#input_data\n",
    "df=pd.DataFrame([])\n",
    "for serial in serial_numbers:\n",
    "    df=df.append(df_segate_backtrack[df_segate_backtrack['serial_number']==serial])\n",
    "\n",
    "target_values=np.array(df['failure']).reshape(-1,1)\n",
    "raw_input=df.drop(columns={'failure'})\n",
    "print(\"shape of test_data: \",raw_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>model</th>\n",
       "      <th>serial_number</th>\n",
       "      <th>capacity_bytes</th>\n",
       "      <th>smart_5_raw</th>\n",
       "      <th>smart_9_raw</th>\n",
       "      <th>smart_12_raw</th>\n",
       "      <th>smart_187_raw</th>\n",
       "      <th>smart_188_raw</th>\n",
       "      <th>smart_190_raw</th>\n",
       "      <th>smart_193_raw</th>\n",
       "      <th>smart_194_raw</th>\n",
       "      <th>smart_197_raw</th>\n",
       "      <th>smart_198_raw</th>\n",
       "      <th>smart_199_raw</th>\n",
       "      <th>smart_241_raw</th>\n",
       "      <th>smart_242_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>ST4000DM000</td>\n",
       "      <td>Z305B2QN</td>\n",
       "      <td>4000787030016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31048.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>34185.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.863399e+10</td>\n",
       "      <td>1.425050e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19569</th>\n",
       "      <td>2019-07-02</td>\n",
       "      <td>ST4000DM000</td>\n",
       "      <td>Z305B2QN</td>\n",
       "      <td>4000787030016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31072.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>34185.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.864971e+10</td>\n",
       "      <td>1.426446e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39137</th>\n",
       "      <td>2019-07-03</td>\n",
       "      <td>ST4000DM000</td>\n",
       "      <td>Z305B2QN</td>\n",
       "      <td>4000787030016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31096.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>34185.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.867670e+10</td>\n",
       "      <td>1.428033e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58705</th>\n",
       "      <td>2019-07-04</td>\n",
       "      <td>ST4000DM000</td>\n",
       "      <td>Z305B2QN</td>\n",
       "      <td>4000787030016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31119.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>34185.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.870182e+10</td>\n",
       "      <td>1.429589e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78272</th>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>ST4000DM000</td>\n",
       "      <td>Z305B2QN</td>\n",
       "      <td>4000787030016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31143.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>34185.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.872082e+10</td>\n",
       "      <td>1.431487e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date        model serial_number  capacity_bytes  smart_5_raw  \\\n",
       "0      2019-07-01  ST4000DM000      Z305B2QN   4000787030016          0.0   \n",
       "19569  2019-07-02  ST4000DM000      Z305B2QN   4000787030016          0.0   \n",
       "39137  2019-07-03  ST4000DM000      Z305B2QN   4000787030016          0.0   \n",
       "58705  2019-07-04  ST4000DM000      Z305B2QN   4000787030016          0.0   \n",
       "78272  2019-07-05  ST4000DM000      Z305B2QN   4000787030016          0.0   \n",
       "\n",
       "       smart_9_raw  smart_12_raw  smart_187_raw  smart_188_raw  smart_190_raw  \\\n",
       "0          31048.0          13.0            0.0            0.0           21.0   \n",
       "19569      31072.0          13.0            0.0            0.0           21.0   \n",
       "39137      31096.0          13.0            0.0            0.0           21.0   \n",
       "58705      31119.0          13.0            0.0            0.0           22.0   \n",
       "78272      31143.0          13.0            0.0            0.0           21.0   \n",
       "\n",
       "       smart_193_raw  smart_194_raw  smart_197_raw  smart_198_raw  \\\n",
       "0            34185.0           21.0            0.0            0.0   \n",
       "19569        34185.0           21.0            0.0            0.0   \n",
       "39137        34185.0           21.0            0.0            0.0   \n",
       "58705        34185.0           22.0            0.0            0.0   \n",
       "78272        34185.0           21.0            0.0            0.0   \n",
       "\n",
       "       smart_199_raw  smart_241_raw  smart_242_raw  \n",
       "0                0.0   4.863399e+10   1.425050e+11  \n",
       "19569            0.0   4.864971e+10   1.426446e+11  \n",
       "39137            0.0   4.867670e+10   1.428033e+11  \n",
       "58705            0.0   4.870182e+10   1.429589e+11  \n",
       "78272            0.0   4.872082e+10   1.431487e+11  "
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['smart_5_raw', 'smart_9_raw', 'smart_12_raw', 'smart_187_raw',\n",
    "       'smart_188_raw', 'smart_190_raw', 'smart_193_raw', 'smart_194_raw',\n",
    "       'smart_197_raw', 'smart_198_raw', 'smart_199_raw', 'smart_241_raw',\n",
    "       'smart_242_raw']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Functions for pre-processing, feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    #filling missing values with mean\n",
    "    for column in columns:\n",
    "        if math.isnan(df[column].mean()):\n",
    "            df[column]=df[column].fillna(0)\n",
    "        else:\n",
    "            df[column]=df[column].fillna(df[column].mean())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_mean_stdev(df):\n",
    "    #calculating rolling_mean, rolling_stdev for smart parameters - window 15\n",
    "    serial_numbers=df['serial_number'].values\n",
    "    serial_number=df['serial_number'].values[0]\n",
    "    for column in columns:\n",
    "        rolling_mean=[]\n",
    "        rolling_stdev=[]\n",
    "        for i in range(df.shape[0]):\n",
    "            if serial_numbers[i]!=serial_numbers[i-1]:\n",
    "                values=[] \n",
    "                values.append(df[column].values[i])\n",
    "                rolling_mean.append(mean(values))\n",
    "                rolling_stdev.append(values[-1])\n",
    "            else:\n",
    "                if(len(values)<15): \n",
    "                    values.append(df[column].values[i])\n",
    "                    mean_=mean(values[0:len(values)])\n",
    "                    stdev_=stdev(values[0:len(values)])\n",
    "                    rolling_mean.append(mean_)\n",
    "                    rolling_stdev.append(stdev_)\n",
    "                else:\n",
    "                    values.append(df[column].values[i])\n",
    "                    mean_=mean(values[len(values)-15:len(values)])\n",
    "                    stdev_=stdev(values[len(values)-15:len(values)])\n",
    "                    rolling_mean.append(mean_)\n",
    "                    rolling_stdev.append(stdev_)\n",
    "        df[column+'_rolling_mean'] = rolling_mean\n",
    "        df[column+'_rolling_stdev'] = rolling_stdev\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expanding_mean_stdev(df):\n",
    "    #calculating expanding_mean, expanding_stdev for smart parameters\n",
    "    serial_numbers=df['serial_number'].values\n",
    "    serial_number=df['serial_number'].values[0]\n",
    "    for column in (columns):\n",
    "        expanding_mean=[]\n",
    "        expanding_stdev=[]\n",
    "        for i in range(df.shape[0]):\n",
    "            if serial_numbers[i]!=serial_numbers[i-1]:\n",
    "                values=[] \n",
    "                values.append(df[column].values[i])\n",
    "                expanding_mean.append(sum(values))\n",
    "                expanding_stdev.append(values[-1])\n",
    "            else:\n",
    "                values.append(df[column].values[i])\n",
    "                expanding_mean.append(mean(values))\n",
    "                expanding_stdev.append(stdev(values))\n",
    "        df[column+'_expanding_mean'] = expanding_mean\n",
    "        df[column+'_expanding_stdev'] = expanding_stdev \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_smoothing(df):\n",
    "    #exponential smoothing for smart parameters with alpha=0.15\n",
    "    serial_numbers=df['serial_number'].values\n",
    "    serial_number=df['serial_number'].values[0]\n",
    "    alpha=0.15\n",
    "    for column in (columns):\n",
    "        predicted_values=[]\n",
    "        for i in range(df.shape[0]):\n",
    "            if serial_numbers[i]!=serial_numbers[i-1]:\n",
    "                predicted_value = (df[column].values)[i]\n",
    "                predicted_values.append(predicted_value)\n",
    "            else:\n",
    "                predicted_value =(alpha*df[column].values[i]) + ((1-alpha)*predicted_value)\n",
    "                predicted_values.append(predicted_value)\n",
    "        df[column+'_exp_avg'] = predicted_values\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_id_features(df):\n",
    "    #Model ID characters count\n",
    "    #saving and loading dicts using pickle\n",
    "    #https://stackoverflow.com/questions/11218477/how-can-i-use-pickle-to-save-a-dict\n",
    "    with open(\"model_char_count.pickle\",\"rb\") as fp:\n",
    "        model_char_count=pickle.load(fp)\n",
    "\n",
    "    keys=model_char_count.keys()\n",
    "    values=model_char_count.values()\n",
    "\n",
    "    model_char_count_test=[]\n",
    "    for model in df['model']:\n",
    "        if model not in keys:\n",
    "            #for model not in train but in cv/test, using most appeared count\n",
    "            model_char_count_test.append(mode(values))\n",
    "        else:\n",
    "            model_char_count_test.append(model_char_count[model])\n",
    "    df['model_char_count']=model_char_count_test\n",
    "\n",
    "    #Model ID second and last characters\n",
    "    with open(\"model_second_last_chars.pickle\",\"rb\") as fp:\n",
    "        second_last_chars=pickle.load(fp)\n",
    "\n",
    "    keys=second_last_chars.keys()\n",
    "    model_second_last_char_test=[]\n",
    "    for model in df['model']:\n",
    "        if model not in keys:\n",
    "            model_second_last_char_test.append('NULL')\n",
    "        else:\n",
    "            model_second_last_char_test.append(second_last_chars[model])\n",
    "    df['model_second_last_char']=model_second_last_char_test\n",
    "\n",
    "    #response coding for Model ID second_last_chars\n",
    "    with open(\"model_prob_dict.pickle\",\"rb\") as fp:\n",
    "        model_prob_dict=pickle.load(fp)\n",
    "    keys=model_prob_dict.keys()\n",
    "    test_model_second_last_char_response_code=[]\n",
    "    for model_second_last_char in df['model_second_last_char']:\n",
    "        if model_second_last_char not in keys:\n",
    "            test_model_second_last_char_response_code.append([0.5,0.5])\n",
    "        else:\n",
    "            test_model_second_last_char_response_code.append(model_prob_dict.get(model_second_last_char))\n",
    "    df['model_second_last_char_working']=np.array(test_model_second_last_char_response_code)[:,0]\n",
    "    df['model_second_last_char_fail']=np.array(test_model_second_last_char_response_code)[:,1]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serial_number_features(df):\n",
    "    #serial_number second, last chars\n",
    "    with open(\"serial_second_last_chars.pickle\",\"rb\") as fp:\n",
    "        serial_second_last_chars=pickle.load(fp)\n",
    "    keys=serial_second_last_chars.keys()\n",
    "    serial_number_second_last_char_test=[]\n",
    "    for serial_number in df['serial_number']:\n",
    "        if serial_number not in keys:\n",
    "            serial_number_second_last_char_test.append('NULL')\n",
    "        else:\n",
    "            serial_number_second_last_char_test.append(serial_second_last_chars[serial_number])\n",
    "    df['serial_number_second_last_char']=serial_number_second_last_char_test\n",
    "    \n",
    "    #response coding for serial_number second_last chars\n",
    "    with open(\"serial_prob_dict.pickle\",\"rb\") as fp:\n",
    "        serial_prob_dict=pickle.load(fp)\n",
    "    keys=serial_prob_dict.keys()\n",
    "    test_serial_number_second_last_char_response_code=[]\n",
    "    for serial_number_second_last_char in df['serial_number_second_last_char']:\n",
    "        if serial_number_second_last_char not in keys:\n",
    "            test_serial_number_second_last_char_response_code.append([0.5,0.5])\n",
    "        else:\n",
    "            test_serial_number_second_last_char_response_code.append(serial_prob_dict.get(serial_number_second_last_char))\n",
    "    df['serial_second_last_char_working']=np.array(test_serial_number_second_last_char_response_code)[:,0]\n",
    "    df['serial_second_last_char_fail']=np.array(test_serial_number_second_last_char_response_code)[:,1]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_50_features():\n",
    "    #all_columns=['model_char_count','model_second_last_char_working','serial_second_last_char_working']\n",
    "    #all_columns.extend(df.columns[3:86])\n",
    "    with open(\"top_50_features.txt\",\"rb\") as fp:\n",
    "        top_50_features=pickle.load(fp)\n",
    "        \n",
    "    return top_50_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    #calculating mean,std,min,max for all the smart parameters row wise in the data\n",
    "    df['mean']=df[columns].mean(axis=1)\n",
    "    df['std']=df[columns].std(axis=1)\n",
    "    df['min']=df[columns].min(axis=1)\n",
    "    df['max']=df[columns].max(axis=1)\n",
    "    \n",
    "    #calculating rolling_mean, rolling_stdev for smart parameters - window 15\n",
    "    df=rolling_mean_stdev(df)\n",
    "    \n",
    "    #calculating expanding_mean, expanding_stdev for smart parameters\n",
    "    df=expanding_mean_stdev(df)\n",
    "    \n",
    "    #exponential smoothing for smart parameters with alpha=0.15\n",
    "    df=exponential_smoothing(df)\n",
    "\n",
    "    #model_id features\n",
    "    df=model_id_features(df)\n",
    "    \n",
    "    #serial_number features\n",
    "    df=serial_number_features(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Final function 1 which takes raw_input values and outputs predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_fun_1(raw_input):\n",
    "    \n",
    "    #pre-processing\n",
    "    raw_input=preprocessing(raw_input)\n",
    "    \n",
    "    #feature engineering\n",
    "    raw_input=feature_engineering(raw_input)\n",
    "    \n",
    "    #get top 50 features of best model\n",
    "    top_50_features=get_top_50_features()\n",
    "    test_df_final=raw_input[top_50_features]\n",
    "    test_df_final_1=test_df_final.as_matrix()\n",
    "    \n",
    "    #loading best model\n",
    "    cal_xgb_model_imp_new = pickle.load(open(\"cal_xgb_model_imp_new.pickle.dat\", \"rb\"))\n",
    "    predictions=cal_xgb_model_imp_new.predict(test_df_final_1)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Final function 2 which takes raw_input values, target values and outputs scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_fun_2(raw_input,target_values):\n",
    "    \n",
    "    #pre-processing\n",
    "    raw_input=preprocessing(raw_input)\n",
    "    \n",
    "    #feature engineering\n",
    "    raw_input=feature_engineering(raw_input)\n",
    "    \n",
    "    #get top 50 features of best model\n",
    "    top_50_features=get_top_50_features()\n",
    "    test_df_final=raw_input[top_50_features]\n",
    "    test_df_final_1=test_df_final.as_matrix()\n",
    "    \n",
    "    #loading best model\n",
    "    cal_xgb_model_imp_new = pickle.load(open(\"cal_xgb_model_imp_new.pickle.dat\", \"rb\"))\n",
    "    predictions=cal_xgb_model_imp_new.predict(test_df_final_1)\n",
    "    f1Score=f1_score(target_values,predictions)\n",
    "    precisionScore=precision_score(target_values,predictions)\n",
    "    recallScore=recall_score(target_values,predictions)\n",
    "    \n",
    "    return f1Score,precisionScore,recallScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Executing final functions to output predictions, scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1. Calling final_fun_1 to output predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 100 predictions:\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "predictions=final_fun_1(raw_input)\n",
    "print(\"First 100 predictions:\\n\", predictions[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 100 target_values:\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#printing target values\n",
    "print(\"First 100 target_values:\\n\",np.concatenate(target_values)[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 100 predictions:\n",
      " [1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Last 100 predictions:\\n\",predictions[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 100 target_values:\n",
      " [1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Last 100 target_values:\\n\",np.concatenate(target_values)[-100:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2. calling final_fun_2 to output scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score:  0.9609856262833675\n",
      "precision score:  0.9915254237288136\n",
      "recall score:  0.9322709163346613\n"
     ]
    }
   ],
   "source": [
    "f1Score,precisionScore,recallScore=final_fun_2(raw_input,target_values)\n",
    "print(\"f1 score: \",f1Score)\n",
    "print(\"precision score: \",precisionScore)\n",
    "print(\"recall score: \",recallScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "\n",
    "1. Best model is XGBClassifier with top 50 important features.\n",
    "\n",
    "    __Hyper-Parameters: n_estimators=1000, max_depth=9__\n",
    "    \n",
    "\n",
    "2. Selected some working, some failed drives for test input data\n",
    "\n",
    "\n",
    "3. Printed predicted outputs and target values in section 5.1. We can observe that the model has predicted well.\n",
    "\n",
    "    __f1 score:  0.9609856262833675__\n",
    "    \n",
    "    __precision score:  0.9915254237288136__\n",
    "    \n",
    "    __recall score:  0.9322709163346613__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
